{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0fc3df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import session_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92875af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "nltk                3.6.2\n",
       "numpy               1.21.5\n",
       "pandas              1.4.2\n",
       "session_info        1.0.0\n",
       "sklearn             1.0.2\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "asttokens                   NA\n",
       "backcall                    0.2.0\n",
       "beta_ufunc                  NA\n",
       "binom_ufunc                 NA\n",
       "bottleneck                  1.3.4\n",
       "cloudpickle                 2.0.0\n",
       "colorama                    0.4.4\n",
       "cython_runtime              NA\n",
       "dateutil                    2.8.2\n",
       "debugpy                     1.5.1\n",
       "decorator                   5.1.1\n",
       "entrypoints                 0.4\n",
       "executing                   0.8.3\n",
       "google                      NA\n",
       "importlib_metadata          NA\n",
       "ipykernel                   6.9.1\n",
       "ipython_genutils            0.2.0\n",
       "jedi                        0.18.1\n",
       "joblib                      1.1.0\n",
       "mkl                         2.4.0\n",
       "mpl_toolkits                NA\n",
       "nbinom_ufunc                NA\n",
       "nt                          NA\n",
       "ntsecuritycon               NA\n",
       "numexpr                     2.8.1\n",
       "packaging                   20.9\n",
       "parso                       0.8.3\n",
       "pickleshare                 0.7.5\n",
       "pkg_resources               NA\n",
       "prompt_toolkit              3.0.20\n",
       "psutil                      5.8.0\n",
       "pure_eval                   0.2.2\n",
       "pyarrow                     3.0.0\n",
       "pydev_ipython               NA\n",
       "pydevconsole                NA\n",
       "pydevd                      2.6.0\n",
       "pydevd_concurrency_analyser NA\n",
       "pydevd_file_utils           NA\n",
       "pydevd_plugins              NA\n",
       "pydevd_tracing              NA\n",
       "pygments                    2.11.2\n",
       "pythoncom                   NA\n",
       "pytz                        2021.3\n",
       "pywintypes                  NA\n",
       "regex                       2.5.112\n",
       "scipy                       1.7.3\n",
       "setuptools                  61.2.0\n",
       "six                         1.16.0\n",
       "stack_data                  0.2.0\n",
       "threadpoolctl               2.2.0\n",
       "tornado                     6.1\n",
       "traitlets                   5.1.1\n",
       "typing_extensions           NA\n",
       "wcwidth                     0.2.5\n",
       "win32api                    NA\n",
       "win32com                    NA\n",
       "win32security               NA\n",
       "zipp                        NA\n",
       "zmq                         22.3.0\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             8.2.0\n",
       "jupyter_client      7.2.2\n",
       "jupyter_core        4.9.2\n",
       "jupyterlab          2.2.6\n",
       "notebook            6.1.6\n",
       "-----\n",
       "Python 3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]\n",
       "Windows-10-10.0.10586-SP0\n",
       "-----\n",
       "Session information updated at 2022-10-25 23:43\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим версии используемых модулей.\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3700e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем из nltk стоп слова для русского и английского языка\n",
    "stop1 = list(stopwords.words('english'))\n",
    "stop2 = list(stopwords.words('russian'))\n",
    "stop3 = ['africa', 'african', 'afrika', 'antigua', 'arab', 'arabia', 'arabiyyah', 'art', 'aş', 'bahamas', 'bahrayn', 'barbuda', 'belgien', 'belgique', 'belgië', 'bielaruś', 'bissau', 'bosnia', 'bukchosŏn', 'bulgariya', 'burkina', 'cabo', 'cape', 'centrafricaine', 'central', 'channel', 'chosŏn', 'città', 'city', 'comores', 'costa', 'crna', 'côte', 'dawlat', 'del', 'democratic', 'dhivehi', 'dominican', 'dominicana', 'dr', 'druk', 'du', 'démocratique', 'east', 'ecuatorial', 'el', 'emirates', 'equatorial', 'faeroe', 'faso', 'federated', 'french', 'gabonaise', 'gora', 'grenadines', 'guiana', 'helena', 'hellas', 'hercegovína', 'herzegovina', 'holy', 'hong', 'ia', 'imārat', 'islands', 'isle', 'ityop', 'ivoire', 'kingdom', 'kitts', 'kong', 'korea', 'koromi', 'kuwayt', 'kıbrıs', 'lanka', 'lankā', 'leone', 'leste', 'lester', 'lucia', 'macedonia', 'makedonija', 'man', 'marino', 'marshall', 'maɣréb', 'micronesia', 'mongol', 'mueang', 'nam', 'nevis', 'new', 'north', 'papua', 'principe', 'raajje', 'república', 'rica', 'république', 'sahara', 'saint', 'sak', 'salvador', 'san', 'sao', 'saudi', 'see', 'severna', 'sierra', 'solomon', 'soomaaliya', 'south', 'srbija', 'sri', 'state', 'states', 'suid', 'são', 'thai', 'timor', 'tobago', 'tome', 'tomé', 'trinidad', 'uburundi', 'ul', 'uls', 'umān', 'united', 'urdun', 'vatican', 'vaticano', 'velo', 'verde', 'vincent', 'việt', 'western', 'yaman', 'yul', 'zbekiston', 'zealand', 'şūmāl', 'ūdiyyah', 'ελλάς', 'κύπρος', 'беларусь', 'србија']\n",
    "stop = stop1 + stop2 + stop3\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Функция для предобработки. Удаление знаков пуктуации, приведение к нижнему регистру, лемматизация.\n",
    "def preprocessing(line):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r'[.,\"\\'-?:!;]', \"\", line)\n",
    "    line = nltk.word_tokenize(line)\n",
    "    line = ' '.join([lemmatizer.lemmatize(w) if w not in stop_words else \"\" for w in line])\n",
    "    return line\n",
    "\n",
    "\n",
    "# Добавим в стоп слова названия стран и слова-формы собственности организаций.\n",
    "df_stop = pd.read_csv('stop_words.csv')\n",
    "df_countries = pd.read_csv('stop_countries.csv', header=None)\n",
    "stop_company = list(df_stop['0'])\n",
    "stop_countries = list(df_countries[1])\n",
    "stop_words = list(set(stop+ stop_company + stop_countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1e7d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Читаем наш датасет.\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22f9e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>name_1</th>\n",
       "      <th>name_2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Iko Industries Ltd.</td>\n",
       "      <td>Enormous Industrial Trade Pvt., Ltd.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Apcotex Industries Ltd.</td>\n",
       "      <td>Technocraft Industries (India) Ltd.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Rishichem Distributors Pvt., Ltd.</td>\n",
       "      <td>Dsa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Powermax Rubber Factory</td>\n",
       "      <td>Co. One</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Tress A/S</td>\n",
       "      <td>Longyou Industries Park Zhejiang</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_id                             name_1  \\\n",
       "0        1                Iko Industries Ltd.   \n",
       "1        2            Apcotex Industries Ltd.   \n",
       "2        3  Rishichem Distributors Pvt., Ltd.   \n",
       "3        4            Powermax Rubber Factory   \n",
       "4        5                          Tress A/S   \n",
       "\n",
       "                                 name_2  is_duplicate  \n",
       "0  Enormous Industrial Trade Pvt., Ltd.             0  \n",
       "1   Technocraft Industries (India) Ltd.             0  \n",
       "2                                   Dsa             0  \n",
       "3                               Co. One             0  \n",
       "4      Longyou Industries Park Zhejiang             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим на данные.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1deaf225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995638\n"
     ]
    }
   ],
   "source": [
    "# Объединим два столбца, посмотрим сколько всего названий.\n",
    "text = list(df['name_1']) + list(df['name_2'])\n",
    "\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c402f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18022\n",
      "18022\n",
      "18022\n"
     ]
    }
   ],
   "source": [
    "# Оставим только уникальные названия.\n",
    "text_unic = list(set(text))\n",
    "\n",
    "text_unic_preproc = [preprocessing(name) for name in text_unic]\n",
    "\n",
    "# Загружаем ранее сохранённый tfidfvectirizer\n",
    "my_vectorizer = pickle.load(open('vectorizer_2.pickle','rb'))\n",
    "\n",
    "# Функция для создания эмбеддингов из названий компаний.\n",
    "def sentence_embedding_fl(string, vectorizer):\n",
    "    tf_vectorizer = vectorizer\n",
    "    sentence_list = [tf_vectorizer.transform([word]).toarray() for word in string.split()]\n",
    "        \n",
    "    result = np.sum(np.array(sentence_list), axis=0)\n",
    "    if len(result.shape) == 0:\n",
    "        result = np.zeros((1,9776))\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "name_embeddings = [sentence_embedding_fl(name, my_vectorizer) for name in  text_unic_preproc]\n",
    "\n",
    "print(len(text_unic))\n",
    "print(len(text_unic_preproc))\n",
    "print(len(name_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc6a6371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним эмбеддинги для названий организаций и ещё сохраним сам список организаций.\n",
    "pickle.dump(name_embeddings, open('name_embeddings.pickle', \"wb\"))\n",
    "pickle.dump(text_unic, open('companies_name_unic.pickle', \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
