{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4431b759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "from heapq import nlargest\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import session_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ea4be22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "nltk                3.6.2\n",
       "numpy               1.21.5\n",
       "pandas              1.4.2\n",
       "session_info        1.0.0\n",
       "sklearn             1.0.2\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "asttokens                   NA\n",
       "backcall                    0.2.0\n",
       "beta_ufunc                  NA\n",
       "binom_ufunc                 NA\n",
       "bottleneck                  1.3.4\n",
       "cloudpickle                 2.0.0\n",
       "colorama                    0.4.4\n",
       "cython_runtime              NA\n",
       "dateutil                    2.8.2\n",
       "debugpy                     1.5.1\n",
       "decorator                   5.1.1\n",
       "entrypoints                 0.4\n",
       "executing                   0.8.3\n",
       "google                      NA\n",
       "importlib_metadata          NA\n",
       "ipykernel                   6.9.1\n",
       "ipython_genutils            0.2.0\n",
       "jedi                        0.18.1\n",
       "joblib                      1.1.0\n",
       "mkl                         2.4.0\n",
       "mpl_toolkits                NA\n",
       "nbinom_ufunc                NA\n",
       "nt                          NA\n",
       "ntsecuritycon               NA\n",
       "numexpr                     2.8.1\n",
       "packaging                   20.9\n",
       "parso                       0.8.3\n",
       "pickleshare                 0.7.5\n",
       "pkg_resources               NA\n",
       "prompt_toolkit              3.0.20\n",
       "psutil                      5.8.0\n",
       "pure_eval                   0.2.2\n",
       "pyarrow                     3.0.0\n",
       "pydev_ipython               NA\n",
       "pydevconsole                NA\n",
       "pydevd                      2.6.0\n",
       "pydevd_concurrency_analyser NA\n",
       "pydevd_file_utils           NA\n",
       "pydevd_plugins              NA\n",
       "pydevd_tracing              NA\n",
       "pygments                    2.11.2\n",
       "pythoncom                   NA\n",
       "pytz                        2021.3\n",
       "pywintypes                  NA\n",
       "regex                       2.5.112\n",
       "scipy                       1.7.3\n",
       "setuptools                  61.2.0\n",
       "six                         1.16.0\n",
       "stack_data                  0.2.0\n",
       "threadpoolctl               2.2.0\n",
       "tornado                     6.1\n",
       "traitlets                   5.1.1\n",
       "typing_extensions           NA\n",
       "wcwidth                     0.2.5\n",
       "win32api                    NA\n",
       "win32com                    NA\n",
       "win32security               NA\n",
       "zipp                        NA\n",
       "zmq                         22.3.0\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             8.2.0\n",
       "jupyter_client      7.2.2\n",
       "jupyter_core        4.9.2\n",
       "jupyterlab          2.2.6\n",
       "notebook            6.1.6\n",
       "-----\n",
       "Python 3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]\n",
       "Windows-10-10.0.10586-SP0\n",
       "-----\n",
       "Session information updated at 2022-10-26 16:04\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим версии используемых модулей.\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1a305a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим ранее сохранённые уникальные навазния компаний.\n",
    "text_unic = pickle.load(open('companies_name_unic.pickle','rb'))\n",
    "\n",
    "# Загрузим ранее сохранённый tfidfvectorizer.\n",
    "my_vectorizer = pickle.load(open('vectorizer_2.pickle','rb'))\n",
    "\n",
    "def sentence_embedding_fl(string, vectorizer):\n",
    "    tf_vectorizer = vectorizer\n",
    "    sentence_list = [tf_vectorizer.transform([word]).toarray() for word in string.split()]\n",
    "        \n",
    "    result = np.sum(np.array(sentence_list), axis=0)\n",
    "    if len(result.shape) == 0:\n",
    "        result = np.zeros((1,9776))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eec0db97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим ранее сохранённые эмбеддинги для названий компаний.\n",
    "name_embeddings = pickle.load(open('name_embeddings.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d19ca02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Топ для вывода и порог для косинусного сходства.\n",
    "top = 5\n",
    "treshold_for_cosine_similarity = 0.5\n",
    "\n",
    "# Функция для поиска топ 5 схожих названий и их вывода.\n",
    "def find_top5(similarity_list, top, treshold):\n",
    "    company_names = []\n",
    "    maximums = nlargest(top, similarity_list)\n",
    "    maximums_treshold = [max for max in maximums if max >= treshold ]\n",
    "    if len(maximums_treshold) > 0:\n",
    "            indexes_set = set()\n",
    "            for maximum in maximums_treshold:\n",
    "                indexes = list(np.where(np.array(similarity_list) == maximum)[0])\n",
    "                for index in indexes:\n",
    "                    if index not in indexes_set:\n",
    "                        indexes_set.add(index)\n",
    "                        company_names.append(text_unic[index])\n",
    "\n",
    "    if len(company_names) < top:\n",
    "        result = company_names\n",
    "    else:\n",
    "        result = company_names[:top]\n",
    "        \n",
    "    \n",
    "    print(\"Косинусное сходство \", [round(float(element),3) for element in maximums])\n",
    "    print()\n",
    "\n",
    "    if len(result) > 0:\n",
    "        for name in result:\n",
    "            print(name)\n",
    "    else:\n",
    "        print('Похожих названий, превышающих порог ',treshold, \" не обнаружено.\" ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "686a233f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Косинусное сходство  [0.447, 0.447, 0.447, 0.355, 0.316]\n",
      "\n",
      "Похожих названий, превышающих порог  0.5  не обнаружено.\n",
      "\n",
      "Время обработки поиска =  10.703\n"
     ]
    }
   ],
   "source": [
    "# Время начала обработки поиска. \n",
    "start_time = time.time()\n",
    "\n",
    "# Тестовый текст 1. Сначала возьмём порог 0.5 для косинусного сходства.\n",
    "my_test_text_1 = 'Darth Vader is a great Sith Lord'\n",
    "\n",
    "# Получим эмбеддинг тестового текста\n",
    "text_vector = sentence_embedding_fl(my_test_text_1, my_vectorizer)\n",
    "\n",
    "# Вычислим косинусное сходство между тестовым текстом и навзаниями компаний.\n",
    "cosine_similarity_list = [cosine_similarity( text_vector, sentence_vector)[0] for sentence_vector in name_embeddings ]\n",
    "\n",
    "find_top5(cosine_similarity_list, top, treshold_for_cosine_similarity)\n",
    "\n",
    "# Время окончания обработки поиска.\n",
    "end_time = time.time()\n",
    "\n",
    "print()\n",
    "print(\"Время обработки поиска = \", round(end_time-start_time, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "603a37fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Видим, что ничего не найдено, так косинусное сходство меньше порога."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e586d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Косинусное сходство  [0.447, 0.447, 0.447, 0.355, 0.316]\n",
      "\n",
      "Lord Industrial Ltda\n",
      "Lord India Pvt., Ltd.\n",
      "Jm Lord International Llc\n",
      "Greatech Philippines Inc.\n",
      "Great Sports Infra Pvt., Ltd.\n",
      "\n",
      "Время обработки поиска =  10.561\n"
     ]
    }
   ],
   "source": [
    "# Время начала обработки поиска. \n",
    "start_time = time.time()\n",
    "\n",
    "# Тестовый текст 1. Теперь возьмём порог 0.3.\n",
    "my_test_text_1 = 'Darth Vader is a great Sith Lord'\n",
    "\n",
    "# Получим эмбеддинг тестового текста\n",
    "text_vector = sentence_embedding_fl(my_test_text_1, my_vectorizer)\n",
    "\n",
    "# Вычислим косинусное сходство между тестовым текстом и навзаниями компаний.\n",
    "cosine_similarity_list = [cosine_similarity( text_vector, sentence_vector)[0] for sentence_vector in name_embeddings ]\n",
    "\n",
    "find_top5(cosine_similarity_list, top, 0.3)\n",
    "\n",
    "# Время окончания обработки поиска.\n",
    "end_time = time.time()\n",
    "\n",
    "print()\n",
    "print(\"Время обработки поиска = \", round(end_time-start_time, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "260e31a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Видим, что к непохожему на название компании тексту нашлись названия, где фигурируют похожие слова \"Lord\" и \"Great\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d887c1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Косинусное сходство  [0.816, 0.577, 0.577, 0.577, 0.577]\n",
      "\n",
      "Powermax Rubber Factory\n",
      "B G N Rubber Factory\n",
      "Western Rubbers India Pvt., Ltd.\n",
      "K.S. Rubbers\n",
      "Imp. Rubbers International Llc\n",
      "\n",
      "Время обработки поиска =  10.67\n"
     ]
    }
   ],
   "source": [
    "# Время начала обработки поиска. \n",
    "start_time = time.time()\n",
    "\n",
    "# Теперь попробуем текст, который был в датасете.\n",
    "my_test_text_2 = 'Powermax Rubber Factory'\n",
    "\n",
    "# Получим эмбеддинг второго тестового текста\n",
    "text_vector2 = sentence_embedding_fl(my_test_text_2, my_vectorizer)\n",
    "\n",
    "# Вычислим косинусное сходство между тестовым текстом и навзаниями компаний.\n",
    "cosine_similarity_list2 = [cosine_similarity( text_vector2, sentence_vector)[0] for sentence_vector in name_embeddings ]\n",
    "\n",
    "find_top5(cosine_similarity_list2, top, 0.3)\n",
    "\n",
    "# Время окончания обработки поиска.\n",
    "end_time = time.time()\n",
    "\n",
    "print()\n",
    "print(\"Время обработки поиска = \", round(end_time-start_time, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7be70114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Видим что на первом месте исходный текст (не удивительно), а дальше тексты с похожими словами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "478e35f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Косинусное сходство  [0.494, 0.45, 0.408, 0.408, 0.408]\n",
      "\n",
      "Honeywell Aerospace Systems Laboratory Co. S. De .R.L. De C.V.\n",
      "Aerocosta Global Systems Inc.\n",
      "Craft Colombia Sas\n",
      "Mx Systems International P Ltd.\n",
      "Craft Argentina S.A.\n",
      "\n",
      "Время обработки поиска =  10.719\n"
     ]
    }
   ],
   "source": [
    "# Время начала обработки поиска. \n",
    "start_time = time.time()\n",
    "\n",
    "# Теперь попробуем текст, не был в датасете, но похож, на то, что был там.\n",
    "# Оригинал: Honeywell Aerospace Systems Laboratory Co. S. De .R.L. De C.V.\n",
    "# Изменённый вариант\n",
    "my_test_text_3 = 'Well Aero System Lab Industrial Craft'\n",
    "\n",
    "# Получим эмбеддинг второго тестового текста\n",
    "text_vector3 = sentence_embedding_fl(my_test_text_3, my_vectorizer)\n",
    "\n",
    "# Вычислим косинусное сходство между тестовым текстом и навзаниями компаний.\n",
    "cosine_similarity_list3 = [cosine_similarity( text_vector3, sentence_vector)[0] for sentence_vector in name_embeddings ]\n",
    "\n",
    "find_top5(cosine_similarity_list3, top, 0.3)\n",
    "\n",
    "# Время окончания обработки поиска.\n",
    "end_time = time.time()\n",
    "\n",
    "print()\n",
    "print(\"Время обработки поиска = \", round(end_time-start_time, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76cf0c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Видим что на первом месте текст, который был изменён а дальше тексты с похожими словами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a48c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Время поиска и вывода похожих названий около 11 секунд. Долго потому что каждый раз поиск запускается для 18022 эмбеддингов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
