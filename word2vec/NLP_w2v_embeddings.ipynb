{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b6c89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import gensim.downloader as api\n",
    "\n",
    "import session_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f494456d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "gensim              4.0.1\n",
       "nltk                3.6.2\n",
       "numpy               1.21.5\n",
       "pandas              1.4.2\n",
       "session_info        1.0.0\n",
       "sklearn             1.0.2\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "Levenshtein                 NA\n",
       "OpenSSL                     21.0.0\n",
       "asttokens                   NA\n",
       "backcall                    0.2.0\n",
       "beta_ufunc                  NA\n",
       "binom_ufunc                 NA\n",
       "boto3                       1.21.32\n",
       "botocore                    1.24.32\n",
       "bottleneck                  1.3.4\n",
       "brotli                      NA\n",
       "cachetools                  4.2.2\n",
       "certifi                     2022.09.24\n",
       "charset_normalizer          2.0.4\n",
       "cloudpickle                 2.0.0\n",
       "colorama                    0.4.4\n",
       "cryptography                3.4.8\n",
       "cython_runtime              NA\n",
       "dateutil                    2.8.2\n",
       "debugpy                     1.5.1\n",
       "decorator                   5.1.1\n",
       "entrypoints                 0.4\n",
       "executing                   0.8.3\n",
       "google                      NA\n",
       "grpc                        1.42.0\n",
       "idna                        3.3\n",
       "importlib_metadata          NA\n",
       "ipykernel                   6.9.1\n",
       "ipython_genutils            0.2.0\n",
       "jedi                        0.18.1\n",
       "jmespath                    0.10.0\n",
       "joblib                      1.1.0\n",
       "mkl                         2.4.0\n",
       "mpl_toolkits                NA\n",
       "nbinom_ufunc                NA\n",
       "nt                          NA\n",
       "ntsecuritycon               NA\n",
       "numexpr                     2.8.1\n",
       "packaging                   20.9\n",
       "parso                       0.8.3\n",
       "pickleshare                 0.7.5\n",
       "pkg_resources               NA\n",
       "prompt_toolkit              3.0.20\n",
       "psutil                      5.8.0\n",
       "pure_eval                   0.2.2\n",
       "pyarrow                     3.0.0\n",
       "pydev_ipython               NA\n",
       "pydevconsole                NA\n",
       "pydevd                      2.6.0\n",
       "pydevd_concurrency_analyser NA\n",
       "pydevd_file_utils           NA\n",
       "pydevd_plugins              NA\n",
       "pydevd_tracing              NA\n",
       "pygments                    2.11.2\n",
       "pythoncom                   NA\n",
       "pytz                        2021.3\n",
       "pywintypes                  NA\n",
       "regex                       2.5.112\n",
       "requests                    2.27.1\n",
       "scipy                       1.7.3\n",
       "setuptools                  61.2.0\n",
       "six                         1.16.0\n",
       "smart_open                  5.1.0\n",
       "socks                       1.7.1\n",
       "stack_data                  0.2.0\n",
       "threadpoolctl               2.2.0\n",
       "tornado                     6.1\n",
       "traitlets                   5.1.1\n",
       "typing_extensions           NA\n",
       "urllib3                     1.26.9\n",
       "wcwidth                     0.2.5\n",
       "win32api                    NA\n",
       "win32com                    NA\n",
       "win32security               NA\n",
       "zipp                        NA\n",
       "zmq                         22.3.0\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             8.2.0\n",
       "jupyter_client      7.2.2\n",
       "jupyter_core        4.9.2\n",
       "jupyterlab          2.2.6\n",
       "notebook            6.1.6\n",
       "-----\n",
       "Python 3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]\n",
       "Windows-10-10.0.10586-SP0\n",
       "-----\n",
       "Session information updated at 2022-10-26 00:13\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим версии используемых модулей.\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bfe0290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем из nltk стоп слова для русского и английского языка\n",
    "stop1 = list(stopwords.words('english'))\n",
    "stop2 = list(stopwords.words('russian'))\n",
    "stop = stop1 + stop2\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Функция для предобработки. Удаление знаков пуктуации, приведение к нижнему регистру, лемматизация.\n",
    "def preprocessing(line):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r'[.,\"\\'-?:!;]', \"\", line)\n",
    "    line = nltk.word_tokenize(line)\n",
    "    line = ' '.join([lemmatizer.lemmatize(w) for w in line])\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4efa6dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Читаем наш датасет.\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d34fe604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>name_1</th>\n",
       "      <th>name_2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Iko Industries Ltd.</td>\n",
       "      <td>Enormous Industrial Trade Pvt., Ltd.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Apcotex Industries Ltd.</td>\n",
       "      <td>Technocraft Industries (India) Ltd.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Rishichem Distributors Pvt., Ltd.</td>\n",
       "      <td>Dsa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Powermax Rubber Factory</td>\n",
       "      <td>Co. One</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Tress A/S</td>\n",
       "      <td>Longyou Industries Park Zhejiang</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_id                             name_1  \\\n",
       "0        1                Iko Industries Ltd.   \n",
       "1        2            Apcotex Industries Ltd.   \n",
       "2        3  Rishichem Distributors Pvt., Ltd.   \n",
       "3        4            Powermax Rubber Factory   \n",
       "4        5                          Tress A/S   \n",
       "\n",
       "                                 name_2  is_duplicate  \n",
       "0  Enormous Industrial Trade Pvt., Ltd.             0  \n",
       "1   Technocraft Industries (India) Ltd.             0  \n",
       "2                                   Dsa             0  \n",
       "3                               Co. One             0  \n",
       "4      Longyou Industries Park Zhejiang             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим на данные.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "150e7025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 497819 entries, 0 to 497818\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   pair_id       497819 non-null  int64 \n",
      " 1   name_1        497819 non-null  object\n",
      " 2   name_2        497819 non-null  object\n",
      " 3   is_duplicate  497819 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 15.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b83a1482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    494161\n",
       "1      3658\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим сколько одинаковых пар, а сколько разных.\n",
    "df.is_duplicate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73ff17b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиваем датафрейм на на части с копиями и без них.\n",
    "df_0 = df[df['is_duplicate'] == 0]\n",
    "df_1 = df[df['is_duplicate'] == 1]\n",
    "\n",
    "name_1_df_0 = list(df_0['name_1'])\n",
    "name_2_df_0 = list(df_0['name_2'])\n",
    "\n",
    "name_1_df_1 = list(df_1['name_1'])\n",
    "name_2_df_1 = list(df_1['name_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6884e68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995638\n"
     ]
    }
   ],
   "source": [
    "# Объединим два столбца, посмотрим сколько всего названий.\n",
    "text = list(df['name_1']) + list(list(df['name_2']))\n",
    "\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c97710db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных названий   18022\n",
      "Количество слов 73720\n",
      "Количество уникальных слов  16046\n"
     ]
    }
   ],
   "source": [
    "# Оставим только уникальные названия.\n",
    "text_unic = list(set(text))\n",
    "\n",
    "print(\"Количество уникальных названий  \" , len(text_unic))\n",
    "\n",
    "# Разобъем все названия на отдельные слова\n",
    "words = []\n",
    "for string in text_unic:\n",
    "    subwords = preprocessing(string).split()\n",
    "    for word in subwords:\n",
    "        words.append(word)\n",
    "\n",
    "print(\"Количество слов\" , len(words))\n",
    "words_unic = list(set(words))\n",
    "print(\"Количество уникальных слов \", len(words_unic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5990ca6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestocean worldwide logistics inc\n"
     ]
    }
   ],
   "source": [
    "print(preprocessing(text[12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49338655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оставим только слова длиннее 1 символа.\n",
    "filtered_words = [w for w in words_unic if len(w) > 1]\n",
    "\n",
    "# Загрузим предобученную модель word2vec на полтора гигабайта\n",
    "word2vec = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a2e8055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция делает эмбеддинг из строки, как сумму эмбеддингов входящих в строку слов\n",
    "def sentence_embedding(string):\n",
    "    sentence_list = [word2vec.get_vector(w) if w in word2vec else np.zeros(300) for w in string.split()  ]\n",
    "    result = np.sum(np.array(sentence_list), axis=0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "714c4c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carlisle coating & waterproofing inc\n",
      "carlisle coating & wtrprfng\n"
     ]
    }
   ],
   "source": [
    "# Пример текста. Предобработаем его, вычислим эмбеддинги, а потом посмотрим на косинусное сходство.\n",
    "text1 = preprocessing('Carlisle Coatings & Waterproofing, Inc.' )\n",
    "text2 = preprocessing('Carlisle Coatings & Wtrprfng')\n",
    "\n",
    "print(text1)\n",
    "print(text2)\n",
    "\n",
    "text1_vec = sentence_embedding(text1)\n",
    "text2_vec = sentence_embedding(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22275b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.84854585]]\n",
      "0.8485458487282259\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на косинусное сходство двух текстов.\n",
    "print(cosine_similarity(text1_vec.reshape(1, -1), text2_vec.reshape(1, -1)))\n",
    "print(cosine_similarity(text1_vec.reshape(1, -1), text2_vec.reshape(1, -1))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b97166b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычислим косинусное сходство для всех пар из нашего датасета.\n",
    "pair_0 = [cosine_similarity(sentence_embedding(item[0]).reshape(1, -1), sentence_embedding(item[1]).reshape(1, -1)) for item in zip(name_1_df_0 ,name_2_df_0 )]\n",
    "pair_1 = [cosine_similarity(sentence_embedding(item[0]).reshape(1, -1), sentence_embedding(item[1]).reshape(1, -1)) for item in zip(name_1_df_1 ,name_2_df_1 )]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8118c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.50184368]]), array([[0.98082832]]), array([[0.]]), array([[0.33745104]], dtype=float32), array([[0.12854507]]), array([[0.84596272]]), array([[0.33577943]], dtype=float32), array([[0.]]), array([[0.28325106]]), array([[0.34646974]]), array([[0.]]), array([[0.54023613]]), array([[0.69775787]]), array([[0.54692054]]), array([[0.12427095]], dtype=float32), array([[0.]]), array([[0.37939467]]), array([[0.57596859]]), array([[0.09194427]]), array([[0.]]), array([[0.08875784]]), array([[0.48656179]]), array([[0.56370787]]), array([[0.626007]]), array([[0.]]), array([[0.33055593]]), array([[0.29227863]]), array([[0.31663013]]), array([[0.61071167]]), array([[0.]]), array([[0.53513233]]), array([[0.817649]], dtype=float32), array([[0.6009203]], dtype=float32), array([[0.38137397]]), array([[0.36928403]]), array([[0.27060674]]), array([[0.45668453]], dtype=float32), array([[0.23539401]]), array([[0.30541746]]), array([[0.19433094]]), array([[0.27887128]]), array([[0.145431]]), array([[0.36155938]]), array([[0.35226595]]), array([[0.28199174]]), array([[0.28900957]], dtype=float32), array([[0.79246017]]), array([[0.35281828]]), array([[0.1724478]]), array([[0.]])]\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на косинусное сходство первых 50 непохожиш пар.\n",
    "print(pair_0[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "665691f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.902885]]), array([[0.74152608]]), array([[0.75264038]]), array([[0.27097568]]), array([[0.71816032]]), array([[0.45783442]]), array([[0.70380785]]), array([[0.93016223]]), array([[0.61920326]]), array([[0.4405077]]), array([[0.78023845]], dtype=float32), array([[0.6673595]], dtype=float32), array([[0.72691861]]), array([[0.84197215]]), array([[0.60947966]]), array([[0.94203689]]), array([[0.]]), array([[0.49931039]]), array([[0.38948551]]), array([[0.89311576]], dtype=float32), array([[0.36861226]], dtype=float32), array([[0.67940065]]), array([[0.81016271]]), array([[0.64658076]], dtype=float32), array([[0.43093696]]), array([[0.82132138]]), array([[1.]]), array([[0.81036796]]), array([[0.]]), array([[0.76877966]]), array([[0.70892515]]), array([[0.4290575]], dtype=float32), array([[0.78059737]]), array([[0.]]), array([[0.]]), array([[0.5575573]]), array([[0.58716923]], dtype=float32), array([[0.61940515]], dtype=float32), array([[0.27922883]]), array([[1.]]), array([[0.7995023]], dtype=float32), array([[0.73255734]]), array([[0.51894225]]), array([[0.41985098]]), array([[0.576472]], dtype=float32), array([[1.]]), array([[0.59022034]]), array([[0.69906947]]), array([[0.4194367]], dtype=float32), array([[0.]])]\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на косинусное сходство первых 50 похожиш пар.\n",
    "print(pair_1[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a55c5375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494161\n",
      "3658\n"
     ]
    }
   ],
   "source": [
    "print(len(pair_0))\n",
    "print(len(pair_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb3808ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201255    40.72660529665433\n",
      "2878    78.6768726079825\n"
     ]
    }
   ],
   "source": [
    "# Выведем долю пар схожих и отличных по косинусному сходству по порогу 0.3\n",
    "pair_0_trashold_05 = [i for i in pair_0 if i < 0.3]\n",
    "pair_1_trashold_05 = [i for i in pair_1 if i>= 0.3]\n",
    "\n",
    "print(len(pair_0_trashold_05), \"  \",len(pair_0_trashold_05)/len(pair_0)*100)\n",
    "\n",
    "print(len(pair_1_trashold_05), \"  \",len(pair_1_trashold_05)/len(pair_1)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4439f169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
